{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Earnings from Census Data with Decision Tree\n",
    "taken from [The Analytics Edge](https://www.edx.org/course/analytics-edge-mitx-15-071x-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Task\n",
    "\n",
    "The United States government periodically collects demographic information by conducting a census.\n",
    "\n",
    "In this problem, we are going to use census information about an individual to predict how much a person earns -- in particular, whether the person earns more than $50,000 per year. This data comes from the UCI Machine Learning Repository.\n",
    "\n",
    "The file `census.csv` contains 1994 census data for 31,978 individuals in the United States.\n",
    "\n",
    "The dataset includes the following 13 variables:\n",
    "\n",
    "- age = the age of the individual in years\n",
    "- workclass = the classification of the individual's working status (does the person work for the federal government, work for the local government, work without pay, and so on)\n",
    "-  education = the level of education of the individual (e.g., 5th-6th grade, high school graduate, PhD, so on)\n",
    "- maritalstatus = the marital status of the individual\n",
    "- occupation = the type of work the individual does (e.g., administrative/clerical work, farming/fishing, sales and so on)\n",
    "- relationship = relationship of individual to his/her household\n",
    "- race = the individual's race\n",
    "- sex = the individual's sex\n",
    "- capitalgain = the capital gains of the individual in 1994 (from selling an asset such as a stock or bond for more than the original purchase price)\n",
    "- capitalloss = the capital losses of the individual in 1994 (from selling an asset such as a stock or bond for less than the original purchase price)\n",
    "- hoursperweek = the number of hours the individual works per week\n",
    "- nativecountry = the native country of the individual\n",
    "- over50k = whether or not the individual earned more than $50,000 in 1994\n",
    "\n",
    "**Predict whether an individual's earnings are above $50,000 (the variable \"over50k\") using all of the other variables as independent variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "1. Read the dataset `census-2.csv`.\n",
    "2. find out the name and the type of the single colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "sklearn classification can only work with numeric values. Therefore we first have to convert all not-numeric values to numeric values.\n",
    "\n",
    "1. copy the dataframe\n",
    "2. in the copy: convert the target column `over50k` to a boolean\n",
    "3. in the copy: convert the not-numeric independent variables (aka features, aka predictors) via `sklearn.LabelEncoder`.\n",
    "\n",
    "See http://pbpython.com/categorical-encoding.html how to use the `sklearn.LabelEncoder` and for further alternatives to convert not-numeric values to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO convert over50k to boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "Separate target variable `over50k` from the independent variables (all others): \n",
    "`over50k -> y, all others -> X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO (hint: use drop(columns,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Then, split the data randomly into a training set and a testing set, setting the `random_state` to 2000 before creating the split. Split the data so that the training set contains 60% of the observations, while the testing set contains 40% of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "Let us now build a classification tree to predict \"over50k\". Use the training set to build the model, and all of the other variables as independent variables. Use `max_depth=3` and the default parameters else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 6\n",
    "\n",
    "Plot the decision tree using `plotting_utilities.plot_decision_tree`\n",
    "- Which are the most important feature? (Root of the Tree)\n",
    "- Which is the next important feature? (2nd Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plotting_utilities import plot_decision_tree, plot_feature_importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 7\n",
    "\n",
    "Plot Top 5 most important features with [plotting_utilities.plot_feature_importances](./plotting_utilities.py).\n",
    "\n",
    "Are these features also the most important in the Decision Tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7\n",
    "- Predict for the test data and \n",
    "- compare with the actual outcome: \n",
    "  - Therefore print the confusion matrix for the test-data and \n",
    "  - calculate the accuracy\n",
    "      - for the trainings-data\n",
    "      - for the test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
